---
title: "Notes and Summary of the paper Seven Myths of Randomization"
author: "Subash Pathak"
date: "January 10, 2020"
output: html_document
---



<div id="seven-myths-of-randomization" class="section level2">
<h2>Seven Myths of Randomization</h2>
<ul>
<li><p><strong>Link to the paper</strong> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5713" class="uri">https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5713</a></p></li>
<li><p><strong>Link to the powerpoint presentation</strong> <a href="https://www.methodologyhubs.mrc.ac.uk/files/9214/3711/9501/Plenary-_Stephen_Senn.pdf" class="uri">https://www.methodologyhubs.mrc.ac.uk/files/9214/3711/9501/Plenary-_Stephen_Senn.pdf</a></p></li>
</ul>
<p>This paper offers some valuable insights into some of the myths of randomisation that seem to be popular among researchers and investigators.Some concerns are related to the practical realities of clinical research on patients, some regarding balance and some regarding the role of conditioning in a valid statistical inference.</p>
<p>Author makes use of an interesting example of game of rolling red and black dice to illustrate his points. Lets assume we want to know the probability of score of sum 10 from the rolling of red and black die. He goes on to list three variants of the game: 1. Variant 1: First state the probaility of 10 and roll the two dice together. The answer would be 4/36=1/12 2. Variant 2: The red die is rolled so that statistician knows the result and he rolls black die afterwards. probability of sum of 10 here would be (1/2* 0)+ (1/2*1/6)=1/12 3. Variant 3: red die is rolled and the score is unknown to statistician. Then he calls the odds and black die is rolled afterwards. It would be equivalent to variant 1.</p>
<p>The author says we can use these three scenarios as an analogy with clinical trial in which covariate information may or may not be available at baseline. In variant 1 there is no information available, in variant 2 there is info available at baseline and in variant 3 it might in principle, be available but nobody has seen it.</p>
<p>Following are seven myths of Randomised clinical trials discussed in this paper:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Myth 1: Patients are treated simultaneously in clinical trials</strong> This myth seems to be surprisingly persistent with critics of randomisation. Generally, patients are entered into clinical trial soon after they are present. The recruitment period might well be longer than the follow up period in which outcomes of the patients are observed. It could be the case that some patients might have completed their trial before others have even started.</p></li>
<li><p><strong>Myth 2: Balance of prognostic factors is necessary for valid inference</strong> Balance of prognostic factors or covariates in a clinical trial may not happen all the time. That doesn’t mean our trial cannot be used to generate statistical inference. The imbalance seen in covariates are only by chance and we cannot think of it as a flawed study. If there is an imbalance in favor of treatment A, one can always find another imbalance that is equally in favor of treatment B if sufficiently many additional baseline characteristics are examined. Thus the imbalances cancel anyway.This source <a href="https://discourse.datamethods.org/t/should-we-ignore-covariate-imbalance-and-stop-presenting-a-stratified-table-one-for-randomized-trials/547/3">here</a> by Professor Frank Harrell provides clear description with simulations on why we should not worry about covariate imbalance in randomised clinical trials.</p></li>
<li><p><strong>Myth 3: Blinding can be carried out effectively without randomisation</strong> Some critics believe that blinding can be carried out effectively without randomisation. In fact randomisation assures maximum unguessability of any sequence of allocation of treatment. We can’t do this effectively with random allocation of patients to different treatments. By definition, randomisation ensures each and every participant has equal and independent probablilty of being allocated to any treatment group in the study which implies the need for strong blinding. If you don’t randomise you have to assume that your strategy has not been guessed by the investigator.Not publishing the block size in your protocol is a classic example.</p></li>
<li><p><strong>Myth 4: Randomisation is insufficient</strong> This is in some sense is not a myth. Randomisation is not fully efficient and there seems to be loss of one patient per factor fitted compared to a completely balanced design which is not usually possible.</p></li>
<li><p><strong>Myth 5: Randomisation precludes balancing covariates</strong> We can build strata and randomise within them. Fisher’s strategy was balance what you can and randomise what you can’t.</p></li>
<li><p><strong>Myth 6: Observed covariates may be ignored because one has randomised</strong> This is the myth even some statisticians seem to believe. To ignore observed prognostics is to treat variant 2 of the game as if it were game 1. In case of game 1, it is necessary to consider with what probability each of the six scores of red die could arrive if it cannot be observed beforehand. However, once we know the score of the red die, this probability is no longer relevant. Also, conditioning on pre-specified prognostic factor seems to increase precision of our estimate increasing statistical power and reducing sample size requirements <a href="https://www.jclinepi.com/article/S0895-4356(03)00379-2/fulltext">Paper Link on this topic</a>.</p></li>
<li><p><strong>Myth 7: Large Trials are more balanced than small ones</strong> Large and small trials are equally balanced. Its just that with larger trials we have narrower confidence limit and even small effect can be observed resulting in small p-values. This advantage of increased mean balance in covariates has been consumed in the form of narrower limits.</p></li>
</ol>
<p><strong>For more details on links and lists of things regarding common statistical myth, following link can be used:</strong></p>
<p><strong>Reference collection to pushback against common statistical myths</strong> <a href="https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787" class="uri">https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787</a></p>
</div>
