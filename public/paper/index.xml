<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper Notes and Review | Residuals</title>
    <link>/paper/</link>
      <atom:link href="/paper/index.xml" rel="self" type="application/rss+xml" />
    <description>Paper Notes and Review</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Paper Notes and Review</title>
      <link>/paper/</link>
    </image>
    
    <item>
      <title>Inappropriate use of Bivariable analysis to screen risk factors for use in Multivariable analysis</title>
      <link>/paper/bvs_method_paper_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/paper/bvs_method_paper_summary/</guid>
      <description>


&lt;div id=&#34;link-to-the-paper&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Link to the paper&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/8699212&#34; class=&#34;uri&#34;&gt;https://www.ncbi.nlm.nih.gov/pubmed/8699212&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The paper goes into in-depth discussion of how selecting variables based on significance achieved using pvalue criterion of less than 0.05 for use in multivariable analysis won’t be able to embrace the confounders sufficient to control for confounding. When we are only looking at bivariable analysis, it only gives us unadjusted association between one single risk factor and our outcome of interest. This won’t tell us anything about intercorrelation or mutual confounding among risk factors. If risk factors (independent variables) are not truly independent of each other, a nonsignificant risk factor in bivariable analysis is not necessarily nonsignificant in multivariable analysis. BVS (Bivariable selection method) could potentially prevent important variable from being included in multivariable model which could lead to distorted or incomplete findings.&lt;/p&gt;
&lt;p&gt;Authors in the paper have shown some hypothetical as well practical examples where they have clearly indicated how BVS method could be problematic when creating multivariable model. In all these examples they have shown how one risk factor could be mutually confounded to other risk factors. If we use BVS method, there is no way we would be able to know mutual confounding among risk factors and this would lead to incorrect or imprecise formulation of multivariable model.&lt;/p&gt;
&lt;p&gt;Some suggestions and alternatives to BVS method:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Investigators should think carefully about the candidate variables that could affect their outcome of interest and use them all in MV model if its only a small set of variables.&lt;/li&gt;
&lt;li&gt;If collinearity exists due to the inclusion of large set of independent variables and the investigator wishes to screen variables in order to avoid collinearity, this type of screening must be based on prior knowledge of the variables or principles of subject matter being studied; alternatively, other special statistical techniques like regularized regression or principal component analysis can be used. The point is that investigator should not let a computer program decide how to handle collinearity. Additionally, BVS method is useless to solve any problem caused by collinearity.&lt;/li&gt;
&lt;li&gt;Only those variables that are known or expected to be risk factors for the outcome by either principles of the study or the prior knowledge of the variables should be included in MV model.&lt;/li&gt;
&lt;li&gt;Independent variables with empty cells in contingency table with discrete outcome can be handled by collapsing the categories or treating the variable as continuous.&lt;/li&gt;
&lt;li&gt;(My suggestion): I think it is important for investigators to think about cause-effect relationship between outcome and risk factors drawing Directed Acyclic Graphs (DAGs). This will bring clarity in the research question being explored and help formulate multivariable model that would reduce confounding and bias in our analysis. (“The book of why: The new science of Cause and effect” by Judea Pearl is an excellent resource to learn about DAGs)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In conclusion, authors point out that testing bivariable association between variables in the data cannot demonstrate whether a variable is a confounder regardless of the types of statistical methods being used. When a confounder exists and is not properly controlled, estimation of the effect of risk factor on outcome is biased and distorted. To sum up, this paper illustrates BVS method is not able to correct for possible confounders, and its use is not an appropriate way to select variables to be used in multivariable analysis.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My Notes from the book Antifragile</title>
      <link>/paper/antifragile/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/paper/antifragile/</guid>
      <description>


&lt;div id=&#34;antifragile-things-that-gain-from-disorder-by-nassim-taleb&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Antifragile: Things that gain from Disorder By Nassim Taleb&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Link to the book&lt;/strong&gt; &lt;a href=&#34;https://www.amazon.com/Antifragile-Things-That-Disorder-Incerto/dp/0812979680&#34; class=&#34;uri&#34;&gt;https://www.amazon.com/Antifragile-Things-That-Disorder-Incerto/dp/0812979680&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Anything that has more upside than downside from random events (or certain shocks) is antifragile; the reverse is fragile. Depriving antifragile systems of stressors, randomness and volatility will do more harm than good. Example: Spending a month in bed without any movement will lead to muscle atrophy and other health hazards in our complex body system.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The rarer the event the less tractable, and the less we know about how frequent its occurence.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We have the illusion that the world functions because of programmed design, university research, and bureaucratic funding, but there is compelling evidence that its just an illusion- the illusion author call &lt;em&gt;lecturing birds how to fly&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Human body is antifragile. Too much regular food is bad for you, and depriving humans of the stressor of hunger may make them live less than their full potential; so all hormesis seems to be doing is reestablishing the natural dosage for food and hunger in humans. In other words, hormesis is the norm anits absence is what hurts us.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It is said that the best horses lose when they compete with slower ones, and win against better rivals. Undercompensation from the absence of stressor, inverse hormesis, absence of challenge , degrades the best of the best.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Risk management professional look in the past for information in the worst case scenario, and use it to estimate future risks. But they never notice that so-called worst case event, when it happened, exceeded the worst case at the time.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Lucretius problem: The fool believes that the tallest mountain in the world will be equal to the tallest one he has observed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When you hear a corporation or debt-laden government trying to reinstill confidence, you know they are fragile, hence doomed.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Just as in matters of seduction, people lend the most to who need them in the least.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Causal Opacity: For complex systems, there are many conveyors of information around us than meet the eye. It is hard to see the arrow from cause to consequence, making much of conventional methods of analysis, in addition to standard logic, inapplicable. Because of nonlinearites, one needs higher visibility than with regular systems.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Taleb’s message to enterpreneurs: Most of you will fail, disrepected, impoverished, but we are grateful for the risks you are taking and the sacrifices you are making for the sake of the economic growth of the planet and pulling others out of poverty. You are at the source of antifragility. Our nation thanks you.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For a self-employed person, a small (nonterminal) mistake is information, valuable information, one that directs him in his adaptive approach; for someone employed in an office setting, a mistake is something that goes into his permanent record, filed in the personnel department. So, we want to avoid even small mistakes in office settings when working for somebody. This avoidance of small mistakes makes the large ones more severe.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Great Turkey Problem: A turkey is fed for a thousand days by a butcher; every day confirms to its staff of analysts that butchers love turkeys “With increased statistical confidence”. The butcher will keep feeding the turkey until a few days before thanksgiving. Then comes that day when it is really not a good idea to be a turkey. So with butcher surprising it, the turkey will have a revision of belief- right when its confidence in the statement that the &lt;strong&gt;the butcher loves turkeys&lt;/strong&gt; is maximal and “it is very quiet” and soothingly predictable in the life of the turkey. The key here is that such a surprise will be a black swan event (rare unpredictable event); but for the turkey, not for the butcher.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This turkey problem tends to prevail in intellectual circles and has a strong ground in social sciences. Mistaking absence of evidence (of harm) for evidence of absence.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We need to learn to think in second steps, chains of consequences and side effects.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One of life’s packages: no stability without volatility.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Iatrogenics: Harm done by the healer, as when doctor’s interventions do more harm than good.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When constrained systems, those hungry for natural disorder, collapse, as they are eventually bound to, since they are fragile, failure is never seen as the result of fragility. Rather, such failure is interpreted as a product of poor forecasting. As with a crumbling sand pile, it would be unintelligent to attribute the collapse of a fragile bridge to the last truck that crossed it, and even more foolish to try to predict in advance which truck might bring it down.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Humans will never be able to turn politics and economics into the tractable randomness of blackjack.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Not seeing a tsunami or an economic event coming is excusable; building something fragile to them is not.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Focus on getting out of Black swan domain (fourth Quadrant), the one in which we have high exposure to rare “tail” events and these events are incomputable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fragility implies more to lose than to gain, equals more downside than upside, equals unfavorable asymmetry. Antifragility implies more to gain than to lose, equals more upside than downside, equals favorable symmetry.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ray Dalio has a rule for someone making speculative bets: “Make sure that the probability of unacceptable (risk of ruin) is nil”&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Stoicism is the domestication, not the elimination, of emotions, so is the barbell a domestication, not the elimination of uncertainty.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We are managed by small (or large) accidental changes, more accidental than we admit.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Resisting new technology is not necessarily irrational; waiting for time to operate its testing might be a valid approach if one holds that we have an incomplete picture of things.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Green lumber fallacy: The situation in which one mistakes a source of necessary knowledge- the greennes of lumber- for another less visible from the outside, less tractable, less narratable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Strip things to their simplest possible model. The more the studies, the less obvious elementary but fundamental things become&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It is just that the things that are implemented tend to want to be born from practice, not theory.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There is such a thing as nonnerdy applied mathematics: find a problem first, and figure out the math that works for it (just as one acquires language), rather than study in a vacuum through theorems and artificial examples.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is not intelligible to me is not necessarily unintelligent- Nietzsche&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you throw cat or a mouse from an elevation of several times their height, they will typically manage to survive. Elephants, by comparison break limbs very easily.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bergson’s razor: a philosopher should be known for one single idea, not more.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you see fraud and don’t say fraud, you are a fraud&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;An academic is not designed to remember his opinions because he doesn’t have any risk from them.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Never ask anyone for their opinions, forecast, or recommendation. Just ask them what they have- or don’t have- in their portfolio.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The definition of the free man, according to Aristotle, is one who is free with his opinions- as a side effects of being free with his time.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The tragedy of Big data: The more variables, the more correlations that can show signficance in the hands of a skilled researcher. Falsity grows faster than information; it is nonlinear with respect to data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;People fit their beliefs to actions rather than fit their actions to their beliefs.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The best way to verify that you are alive is by checking if you like variations.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Notes and Summary of the paper Seven Myths of Randomization</title>
      <link>/paper/seven_myths_of_randomisation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/paper/seven_myths_of_randomisation/</guid>
      <description>


&lt;div id=&#34;seven-myths-of-randomization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Seven Myths of Randomization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Link to the paper&lt;/strong&gt; &lt;a href=&#34;https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5713&#34; class=&#34;uri&#34;&gt;https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.5713&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Link to the powerpoint presentation&lt;/strong&gt; &lt;a href=&#34;https://www.methodologyhubs.mrc.ac.uk/files/9214/3711/9501/Plenary-_Stephen_Senn.pdf&#34; class=&#34;uri&#34;&gt;https://www.methodologyhubs.mrc.ac.uk/files/9214/3711/9501/Plenary-_Stephen_Senn.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This paper offers some valuable insights into some of the myths of randomisation that seem to be popular among researchers and investigators.Some concerns are related to the practical realities of clinical research on patients, some regarding balance and some regarding the role of conditioning in a valid statistical inference.&lt;/p&gt;
&lt;p&gt;Author makes use of an interesting example of game of rolling red and black dice to illustrate his points. Lets assume we want to know the probability of score of sum 10 from the rolling of red and black die. He goes on to list three variants of the game: 1. Variant 1: First state the probaility of 10 and roll the two dice together. The answer would be 4/36=1/12 2. Variant 2: The red die is rolled so that statistician knows the result and he rolls black die afterwards. probability of sum of 10 here would be (1/2* 0)+ (1/2*1/6)=1/12 3. Variant 3: red die is rolled and the score is unknown to statistician. Then he calls the odds and black die is rolled afterwards. It would be equivalent to variant 1.&lt;/p&gt;
&lt;p&gt;The author says we can use these three scenarios as an analogy with clinical trial in which covariate information may or may not be available at baseline. In variant 1 there is no information available, in variant 2 there is info available at baseline and in variant 3 it might in principle, be available but nobody has seen it.&lt;/p&gt;
&lt;p&gt;Following are seven myths of Randomised clinical trials discussed in this paper:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Myth 1: Patients are treated simultaneously in clinical trials&lt;/strong&gt; This myth seems to be surprisingly persistent with critics of randomisation. Generally, patients are entered into clinical trial soon after they are present. The recruitment period might well be longer than the follow up period in which outcomes of the patients are observed. It could be the case that some patients might have completed their trial before others have even started.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Myth 2: Balance of prognostic factors is necessary for valid inference&lt;/strong&gt; Balance of prognostic factors or covariates in a clinical trial may not happen all the time. That doesn’t mean our trial cannot be used to generate statistical inference. The imbalance seen in covariates are only by chance and we cannot think of it as a flawed study. If there is an imbalance in favor of treatment A, one can always find another imbalance that is equally in favor of treatment B if sufficiently many additional baseline characteristics are examined. Thus the imbalances cancel anyway.This source &lt;a href=&#34;https://discourse.datamethods.org/t/should-we-ignore-covariate-imbalance-and-stop-presenting-a-stratified-table-one-for-randomized-trials/547/3&#34;&gt;here&lt;/a&gt; by Professor Frank Harrell provides clear description with simulations on why we should not worry about covariate imbalance in randomised clinical trials.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Myth 3: Blinding can be carried out effectively without randomisation&lt;/strong&gt; Some critics believe that blinding can be carried out effectively without randomisation. In fact randomisation assures maximum unguessability of any sequence of allocation of treatment. We can’t do this effectively with random allocation of patients to different treatments. By definition, randomisation ensures each and every participant has equal and independent probablilty of being allocated to any treatment group in the study which implies the need for strong blinding. If you don’t randomise you have to assume that your strategy has not been guessed by the investigator.Not publishing the block size in your protocol is a classic example.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Myth 4: Randomisation is insufficient&lt;/strong&gt; This is in some sense is not a myth. Randomisation is not fully efficient and there seems to be loss of one patient per factor fitted compared to a completely balanced design which is not usually possible.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Myth 5: Randomisation precludes balancing covariates&lt;/strong&gt; We can build strata and randomise within them. Fisher’s strategy was balance what you can and randomise what you can’t.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Myth 6: Observed covariates may be ignored because one has randomised&lt;/strong&gt; This is the myth even some statisticians seem to believe. To ignore observed prognostics is to treat variant 2 of the game as if it were game 1. In case of game 1, it is necessary to consider with what probability each of the six scores of red die could arrive if it cannot be observed beforehand. However, once we know the score of the red die, this probability is no longer relevant. Also, conditioning on pre-specified prognostic factor seems to increase precision of our estimate increasing statistical power and reducing sample size requirements &lt;a href=&#34;https://www.jclinepi.com/article/S0895-4356(03)00379-2/fulltext&#34;&gt;Paper Link on this topic&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Myth 7: Large Trials are more balanced than small ones&lt;/strong&gt; Large and small trials are equally balanced. Its just that with larger trials we have narrower confidence limit and even small effect can be observed resulting in small p-values. This advantage of increased mean balance in covariates has been consumed in the form of narrower limits.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;For more details on links and lists of things regarding common statistical myth, following link can be used:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reference collection to pushback against common statistical myths&lt;/strong&gt; &lt;a href=&#34;https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787&#34; class=&#34;uri&#34;&gt;https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Notes and Summary of the paper The primary outcome fails- What next?</title>
      <link>/paper/primary-outcome-negative/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/paper/primary-outcome-negative/</guid>
      <description>


&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Link to the paper&lt;/strong&gt; &lt;a href=&#34;https://www.nejm.org/doi/full/10.1056/NEJMra1510064&#34; class=&#34;uri&#34;&gt;https://www.nejm.org/doi/full/10.1056/NEJMra1510064&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Authors in this paper have made some valuable practical suggestions regarding how we want to look at the results of a trial if its primary outcomes fails to show what we expected. A lot of trials seem to be focused on using statistical significance of p value less than 0.05 as a conclusion of success in the trial. We want to look at the totality of the evidence rather than being focused on statistical significance if we want to evaluate trial results in a practical way. For example, we need to look at the uncertainty surrounding our estimate (effect size) paying attention to confidence interval. Overly simplistic view of p value being greater than 0.05 is a negative result is not an useful strategy to assess trial results. This paper motivates us to ask some important questions after the primary outcome in our clinical trial fails to acheive 5% level of signficance.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is there some indication of potential benefit?&lt;/li&gt;
&lt;li&gt;Was the trial underpowered?&lt;/li&gt;
&lt;li&gt;Was the primary outcome appropriate (or accurately defined)?&lt;/li&gt;
&lt;li&gt;Was the population appropriate?&lt;/li&gt;
&lt;li&gt;Was the treatment regimen appropriate?&lt;/li&gt;
&lt;li&gt;Were there deficiencies in trial conduct?&lt;/li&gt;
&lt;li&gt;Is a claim of noninferiority of value?&lt;/li&gt;
&lt;li&gt;Do subgroup findings elicit positive signals?&lt;/li&gt;
&lt;li&gt;Do secondary outcomes reveal positive findings?&lt;/li&gt;
&lt;li&gt;Can alternative analyses help?&lt;/li&gt;
&lt;li&gt;Does more positive external evidence exist?&lt;/li&gt;
&lt;li&gt;Is there a strong biologic rationale that favors the treatment?&lt;/li&gt;
&lt;/ul&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Is there some indication of potential benefits?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We need to think carefully when we are inferring the signal of treatment benefit with p values greater than 0.05. In PERFORM trial,there was no significant difference between two arms with respect to the composite primary outcome of Ischemic stroke, MI or other vascular casue of death (HR=1.02, 95% CI=(0.94,1.12)). This trial was stopped early because of futility and no safety advanatges were observed for treatment. It was a negative trial. However,TORCH trial, with pvalue of 0.052 for the primary outcome of death from any cause was received with more constructive interpretation. It showed signficant benefits in treatment arm compared to placebo.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Was the trial underpowered&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Lack of enough sample size in a study increases the risk that a signficant benefit will not be shown, event if such an effect exists (type 2 error). In trial of bisoprolol vs. placebo with 621 patients HR was 0.8 (9% CI=0.56 to 1.15; p=0.22) with respect to the primary outcome of death from any cause. When they conducted subsequent CIBIS II trial with 2647 patients HR was 066 (95% CI+0.54, 0.81; p&amp;lt;0.0001). In former case, the trial was too small to detect modest treatment effects. A well powered study requires accrual of sufficient number of primary events which can be acheived by recruiting more patients.&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Was the priamry outcome appropriate (accurately defined)&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The use composite primary outcome increases the number of primary events but doesn’t necessarily increase statistical power. In PROactive trial, pioglitazone was compared with placebo in patients with type 2 diabetes with respect to primary outcome of death from MI, stroke, acute coronary syndrome, endovascular surgery or leg imputation. With 514 trt events and 572 placebo events, pvalue was 0.08. When the outcome used was death from MI (more conventional outcome), 301 events in trt arm and 358 events in placebo gave p value of 0.03. Thus the addition of extra components merely contributed random noise, thereby diluting a potentially real effect into significance.&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Was the population appropriate&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another question to ask when get negative outcomes is whether the wrong patient population was studied.Drug Ivabradine did not show any treatment benefits among patients with stable coronary disease in SIGNIFY and BEAUTIFUL trials. However, in SHIFT trial, which involved patients with chronic heart failure, the incidence of the primary outcome, cardiovascular death or hospitalization for heart failure, was 26% lower with ivabradine than with placebo (p&amp;lt;0.0001). Selection of the appropriate population on the basis of mechanistic effects and preliminary studies is essential for pivotal trial success.&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Was the treatment regimen appropriate&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Determination of dosage regimen for a new drug in a pivotal trial can be challenging. Some trials seem to minimize this risk of under-dosing or overdosing regimen by having a three group design that includes two dosage regimesn for the new drug. For example; in PEGASUS-TIMI trial, 60 mg dose of ticagrelor bested both a 90 mg dose and placebo for long-term use beyond 1 year after mypcardial infarction.&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Were there deficiencies in trial conduct&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Adherence to the study protocol is one of the most important factors for the success of a trial. In case of negative outcomes, we need to ask if there were any issues with adherence to the drugs regimens among patients. sometimes, lack of adherence in a certain site might skew the results. This leads to nonsignficant treatment benefits.&lt;/p&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Is a claim of noninferiority of value&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Can we claim noninferiority after the treatment fails to show superiority? We can claim noninferiority only if the treatment is less invasive or has fewer side effects and noninferiority hypothesis was prespecified in the study protocol.&lt;/p&gt;
&lt;ol start=&#34;8&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Do subgroups findings elicit positive signals&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Subgroup analysis results can be misleading. We need to consider everybody enrolled in the trial for a reliable analysis.Any positive results obtained using subgroups should not be used to make any kind of inference about the drug. At best, it can be used to generate hypothesis for future experiments.&lt;/p&gt;
&lt;ol start=&#34;9&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Do secondary outcomes reveal positive findings&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If the primary outcome is negative, positive findings for secondary outcomes are usually considered to be hypothesis-generating. Although regulatory approval of drug based on strong secondary findings are less likely to happen, sometimes they provide compelling enough evidence to affect guidelines and practice.&lt;/p&gt;
&lt;ol start=&#34;10&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Can alternative analysis help&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Following alternative analysis approach can be helpful in understanding the outcomes better:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Covariate adjusted analysis: Adjusting for baseline covariates strongly related to primary outcome increase precision and statistical power compared to univariate analysis. We always need to prespecify set of covariates in our plan for covariates adjusted model.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;As treated or per-protocol analysis: Analysis conducted based on intention to treat principle should always be the main method for comparing active treatment benefits with respect to placebo in a trial. However, when the trial results go negative based on ITT analysis, arguments are advanced that nonadherence and treatment crossovers may hav masked real treatment effects and that as-treated or per-protocol analyses may get closer to the truth. Unfortunately, use of per-protocol analysis introduces selection bias since we are only looking at subset of patients who adhered and did well in the study. Patients who do not adhere to the treatment regimen and those who cross over to different treatment strategy may have a prognosis that is unrelated to actual treatment. Therefore, such analyses are less likely to influence conclusions regarding treatment efficacy based on ITT principle. However, per-protocol analysis may be considered when examining safety issues.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Analyses of Repeat Events: We lose statistical power and underestimate the benefit of treatment effect by ignoring repeated events that occur subsequently. In studies of chronic diseases such as heart failure, conventional composite outcome analyses concentrate on the time to the first event and ignore any recurrent events. Authors have given an exmple of CHARM trial where ignoring repeated event resulted in underestimating treatment benefit.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;11&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Does more positive external evidence exist&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When we see negative outcome results for an adequately powered trial given preexisting evidence of positive treatment benefit, we need to scrutinize the strength and quality of prior studies. Nonrandomized comparisons and surrogate end points from prior trials are not strong evidence. Evidence from analogous trials and meta-analyses invoving similar types of patients, treatments and outcomes are more valuable. However, favorable findings from meta-analyses should be interpreted cautiously, given the variations across trials in patient selection, the actual treatments studied, and definitions of outcomes and other differences in trial design and conduct. In general, evidence from one large, adequately powered randomized is preferred to that of meta-analysis of smaller studies. Discrepancies between a large trial and a prior meta-analysis warrant further studies to resolve these inconsistencies.&lt;/p&gt;
&lt;ol start=&#34;12&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Is there a strong biologic rationale that favors the treatment&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We need to be wary of arguments when talking about biologic rationale. Almost all phase 3 trials are likely to have enough supportive scientific evidence from animal studies and early-phase trials. However, we have a lot of phase 3 trials that failed to show any signs of efficiacy regardless success in early phase trials. If methodologic flaws in a trails are not the cause of treatment failure, it is usually time to move on, while trying to understand the biologic reasons for failure.&lt;/p&gt;
&lt;p&gt;After carefully, assessing above 12 questions when the primary outcomes of our trial appears negeative, authors have suggested to divert their decisons regarding the drug in the following ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Declare that the trial is positive&lt;/li&gt;
&lt;li&gt;Improve the decision of future trials&lt;/li&gt;
&lt;li&gt;Abandon the treatment as ineffective&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Notes and Summary of the paper The primary outcome is positive- Is that Good Enough ?</title>
      <link>/paper/primary-outcome-positive/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/paper/primary-outcome-positive/</guid>
      <description>


&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Link to the paper&lt;/strong&gt; &lt;a href=&#34;https://www.nejm.org/doi/full/10.1056/NEJMra1601511&#34; class=&#34;uri&#34;&gt;https://www.nejm.org/doi/full/10.1056/NEJMra1601511&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It is often the case that people tend to simplify positive results from a trial as a binary conclusion. However, positive results from primary findings do not guarantee everything done during the course of study was successful and well planned. The authors have presented their arguments saying that determination whether findings provide evidence that is sufficient to modify medical practice requires in depth interpretation of the trial data and the results of earlier related trials. This paper lays out some important questions regarding what we need to think about even if we see positive primary outcome. Usually, the acheivement of statistical signficance for the primary outcome seems to be a prerequisite for the adoption of a new therapy, but it is not sufficient. Authors in this review article have laid out following questions to ask when you see positive primary outcome in your study:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Does a P value of &amp;lt;0.05 provide strong enough evidence?&lt;/li&gt;
&lt;li&gt;What is the magnitude of the treatment benefit?&lt;/li&gt;
&lt;li&gt;Is the primary outcome clinically important (and internally consistent)?&lt;/li&gt;
&lt;li&gt;Are secondary outcomes supportive?&lt;/li&gt;
&lt;li&gt;Are the principal findings consistent across important subgroups?&lt;/li&gt;
&lt;li&gt;Is the trial large enough to be convincing?&lt;/li&gt;
&lt;li&gt;Was the trial stopped early?&lt;/li&gt;
&lt;li&gt;Do concerns about safety counterbalance positive efficacy?&lt;/li&gt;
&lt;li&gt;Is the efficacy-safety balance patient-specific?&lt;/li&gt;
&lt;li&gt;Are there flaws in trial design and conduct?&lt;/li&gt;
&lt;li&gt;Do the findings apply to my patients?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will be summarizing and reviewing these questions based on how they are presented in this paper.&lt;/p&gt;
&lt;p&gt;1.&lt;strong&gt;Does a P value of &amp;lt;0.05 provide strong enough evidence ?&lt;/strong&gt; According to the authors, if we are looking for strong enough evidence of efficay in a trial based on p-value criterian of &amp;lt;0.05, smaller pvalue is always better.They argue PARADIAM-HF trial of sacubitrilvalsartan versus enalapril in patients with heart failure showed overwhelming benefit (p&amp;lt;0.00001) with respect to the composite primary outcome cardiovascular death or hospitalization for heart failure which justified in regulatory approval and clinical adoption of this drug. In contrast to this,NXY-059 of SAINT I trial compared with placebo patients for the treatment of ischemic stroke (primary outcome: disability at 90 days) did not provide strong evidence of efficiency with a small pvalue of 0.038. This caused them to conduct a second SAINT II trial that revealed no signficant effect (p value of 0.33). I am assuming when approving or rejecting the adoption of these drugs they also looked at other metrics of drug evaluation like how big is the effect size (clinically meaningful), confidence intervals etc.. besides p-values.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;What is the magnitude of the treatment effect&lt;/strong&gt; Treatment effect needs to be clinically meaningful (large enough to matter) beyond statistical significance and their determination requires examination of treatment effect on both a relative scale (eg. by calculation of relative risk or hazard ratio) and an absolute scale (eg. by calculation of the differences in the rates of events during follow-up and in the number needed to treat). The extent of uncertainty associated with the effect size should be considered by examining 95% confidence interval. For example, in IMPROVE-IT trial, for ezetimibe compared with placebo in patients with acute coronary syndromes who were being treated with simvastatin, the hazard ratio for the composite primary outcome of cardiovascular death,myocardial infarction, unstable angina, revascularization, or stroke was 0.94 (95% confidence Interval [CI], 0.89 to .98; p=0.016). The 7-year primary event rates were 32.7% with ezetimibe versus 34.7% with placebo (difference of 2% points, CI=around 0 to 4% points). Although findings of the trial were described as positive,small effect size caused to question whether the benefit of ezetimibe is large enough to warrant its cost and potential implications.An advisory panel from FDA recommended against expanding the ezetimibe label to including an indication for a reduction in cardiovascular events.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Is the primary outcome clinically important (and internally consistent)?&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Surrogate points Phase 3 trials are usually powered to achieve clinically relevant, but some diseases use of surrogate primary outcome measure has been accepted. (eg. a reduction in glycated hemoglobin levels as an indication of antiglycemic efficacy in patients with diabetes).Some large scale trials have raised questions regarding the wisdom of such reliance on surrogate markers. In ACCORD trial, intensive therapy resulted in markedly lower glycated hemoglobin levels than standard therapy, but the rate of cardiovascular events was not significantly lower, and mortality was higher. Similarly, in LIDO trial, the approval of the drug levosimendan which resulted in greater hemodynamic improvement (the primary surrogate outcome) than dobutamine patients with acute heart failure was not accepted by FDA. The reason was, SURVIVE, a larger , subsequent trial of levosimendan vs. dobutamine showed no evidence of a treatment benefit for the primary outcome (180 day mortality).&lt;/li&gt;
&lt;li&gt;Composite outcomes Positive composite outcomes must be carefully inspected to determine which components are driving the result. As an example, in RITA trial,fewer patients in intervention group had composite primary outcome of death,myocardial infarcation or refractory angina than compared to conservative group (9.6% vs. 14.5%, p=0.001)&amp;gt; In fact, the result in the difference was driven by halving of the rate of refractory angina, with no evidence of difference in deaths or myocardial infarction at short term.. Fortunately, a 5 year follow up study showed a 22% lower risk of death or myocardial infarcation with the use of interventional approach vs. conservative approach. This lead to the supported use of early interventional approach in patients with accute coronary syndromes to improve diagnosis. In short,When analysing composite outcome we need to parse out which component seems to be driving majority of the outcome results and approach the analysis accordingly.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Are seconadry outcomes supportive&lt;/strong&gt; Confidence in the overall positive results of primary outcome is enhanced if prespecified secondary outcomes also show treatment benefit. For example, people had doubts about positive primary outcome in SAINT I trial of NXY-059 in acute ischemic stroke as prespecified secondary outcomes- scores on the National institutes of Health Stroke Scale and the Barthel Index showed no evidence of benefit between two treatment groups. Secondary outcomes can be helpful in making sure positive primary outcome results are strong enough to believe.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Are findings consistent across subgroups?&lt;/strong&gt; Relative treatment effects may vary according to patient characteristics. Also,consistent relative treatment effect may be observed across all patient types except for certaing high risk subgroups who may have greater absolute benefits. Sometimes, subgroup analysis identify patients who do not appear to benefit from new treatment despite the primary findings being positive. Subgroup analysis could be showing spurious findings only. However, protecting such patients from ineffective treatment should be considered depending on the strength of statistical interaction and its biologic plausability.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Is the trial large enough to be convincing?&lt;/strong&gt; We need to be cautious about being confident on the positive primary findings obtained from small trials. Due to the lack of enough sample size, small trials lack power to detect the true signals; so, positive treatment effects are susceptible to exaggeration and false positives.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Was the trial stopped early&lt;/strong&gt; Sometimes a trial is stopped early because interim results show strong evidence of treatment superiority, which is often a newsworthy event. Unfortunately, this practice tends to exaggerate treatment efficacy. As trial progresses, the estimated treatment effect varies randomly in relation to the true effect. If the interim estimate is based on randomly high indication of efficacy, it is more likely to cross a stopping boundary and to convince a data and safety monitoring board that overwhelming evidence of benefit exists. Stopping early also truncates eveidence for important secondary (and safety) outcomes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Do concerns about safety counterbalance positive efficacy?&lt;/strong&gt; When a new treatment has superior efficacy, it is important to identify concerns about safety that might offset the benefits. A balanced account of both efficacy and safety must be provided. Absolute benefits and risks should be presented in terms of differences and percentages. Consideration of number needed to treat for benefit vs. the number needed to harm may provide a guide to net clinical benefit.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Is the balance of efficacy and safety patient specific?&lt;/strong&gt; The net clinical benefit of a new treatment may be patient-specific- that is, worthwhile for those at an increased risk for the primary efficacy outcome but deleterious for those at an increased risk of adverse events.Calculating the individual patient trade-offs between efficacy and safety is not straightforward, and statistical modeling techniques may be useful.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Are there flaws in trial design or conduct?&lt;/strong&gt; A highly signficant result of the primary outcome could be attributed merely to chance. Also, biases in design and conduct of the trial needs to be ruled out as much as possible for acknowledging genuine benefit. For example, in SIMPLICITY HTN-2 trial, at 6 months, treatment group showed markedly lower systolic blood pressure than compared to control group. However, since it was an open label study, the absence of blinding showed major issues like placebo and Hawthorne effects, ascertainment bias and regression to the mean. Limitations in the completeness and quality of the data can also corrupt the validity of the trial. Judgement is required in determining whether the extent of nonadherence or withdrawals casts doubt on the legitimacy of the trial.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Do the findings apply to my patients&lt;/strong&gt; When we look at findings of a trial, we need to think of whether the results can be generalized to other patients besides the group represented in the trial. For example, SPRINT trial excluded patients younger than 50 years of age and those with diabetes and history of stroke. The trial results seem to apply to only about 20% of patients with hypertension who are seen in practice. Geographic representation in atrial may also affect generalizability of its results.If patient recruitment is dominated by one region, worldwide applicability may be limited. In addition, genetic, anatimical,environmental,and dietary differences among peoples sometimes makes outcomes difficult to generalize across countries.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Authors of this paper concluded with some good remarks for evaluating study results for new drugs. Deeper inspection of study processes and outcomes is need even thoug the study has achieved statistical signficance. If the efficacy and safety outcomes of the trial are convincingly met, the next step is to evaluate its overall quality and internal validity. We also need to determine whether the findings translate into treatment effectiveness in real-world patients.We need to be cautious about investigating selection bias and residual confounding when nonrandomized registries are used to confirm or refute trial findings. For new drug, regulatory requirements for approval depends on totality of the evidence from the trial and from all previous related studies.&lt;/p&gt;
&lt;p&gt;Overall, this paper provides key guidance regarding the questions to ask in case of a positive primary outcome in a trial. Considering these above mentioned questions when working towards approval of a certain treatment help improve quality of approval process as well treatment in general. However, ultimately, physicians at the point of care bear final responsibility for accuarately interpreting clinical trial results and for integrating regulatory and guideline recommendations in order to make the best treatment decisions for each patient in their care.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
